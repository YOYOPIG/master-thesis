\documentclass{PHlab-thesis}

\addbibresource{thesis.bib}

\newcommand*\Department中文{資訊工程學研究所}
\newcommand*\Department英文{Institute of Computer Science and Information Engineering}

\newcommand*\ThesisTitle中文{EAGLE-GPU：使用圖形處理單元加速替代基因組可能性評估}
\newcommand*\ThesisTitle英文{EAGLE-GPU: Acceleration of Alternative Genome Likelihood Evaluation using Graphics Processing Unit}
%\newcommand*\ThesisNote中文{示例:其實徐翡曼是東京大學畢業的博士}% For real thesis omit, or use {初稿} etc.
%\newcommand*\ThesisNote英文{Just an example.  Fei-Man actually graduated from Tokyo Univ.}% For real thesis omit, or use {draft} etc.

\newcommand*\Student中文{盧宥霖}
\newcommand*\Student英文{You-Lin Lu}

\newcommand*\Advisor中文{賀保羅}
\newcommand*\Advisor英文{Paul Horton}

%% 果有共同指導老師可以用:
%% \newcommand*\CoAdvisorA中文{}
%% \newcommand*\CoAdvisorA英文{}
%% \newcommand*\CoAdvisorB中文{}
%% \newcommand*\CoAdvisorB英文{}


\newcommand*\YearMonth英文{July, 2022}
\newcommand*\YearMonth中文{１１１年７月}


\begin{document}


\newcommand*\Keywords英文{genomics, variant calling, GPU acceleration}
\newcommand*\Abstract英文{%TODO
We introduce MethylSeqLogo, an extension of sequence logos to vizualize DNA methylation.
}


\newcommand*\Keywords中文{基因組、字串演算法}
\newcommand*\Abstract中文{%TODO
MethylSeqLogo...衍伸sequence logo的視覺化方法改善包括DNA甲基化的資訊。
}

\newcommand*\Acknowledgements{%
Thank you Prof. Horton%
}



\input{frontmatter}% 封面頁, 口委中英文簽名單, 誌謝, 中英文摘要, 論文目錄, 圖表目錄


%────────────────────  List of Symbols  ────────────────────
\renewcommand\nomgroup[1]{%
  \item[\bfseries
  \ifstrequal{#1}{A}{General}{%
  \ifstrequal{#1}{Z}{Gene/Protein Names}%
  }]}

\nomenclature[A]{$\lg$}{Logarithm base 2}
\nomenclature[A]{KL\ Divergence}{Kullback-Liebler Divergence}
\nomenclature[Z]{Myc}{MYC proto-oncogene}
\nomenclature[Z]{USF-1}{Upstream stimulatory factor 1}

\printnomenclature[5cm]

\newpage
\setcounter{page}{1}
\pagenumbering{arabic}


\chapter{Introduction}
Next generation sequencing has played a significant role in bioinformatics research for the past decades~\cite{behjati2013next,schuster2008next}. This technology enables sequencing the whole human genome sequence in a relative short amount of time, allowing more advanced biological analysis and even medical applications~\cite{roukos2010next}. For example, numerous genetic and epigenetic mechanisms, such as DNA mutation and methylation, could be scrutinized if the accurate genome sequencing data is available~\cite{moore2013dna}. Better knowledge of the human genome system thus makes great impact to clinical practices, notably the diagnosis of hereditary diseases and those related to genetic disorders~\cite{shashi2014utility,stenson2017human}, including specific subtypes of cancer~\cite{serrati2016next}.
Despite the breakthroughs made by utilizing NGS results, several underlying obstacles, however, still exists in the sequencing pipeline. Since sequencers are unable to produce reads as long as the whole human genome sequence without errors, the sequencing results often come in as multiple shorter read segments, leading to that analysis and data processing should be done in advance for researchers to gain insights~\cite{muzzey2015understanding}. Among them, variant calling remains to be a challenging subtask. Various methods have been proposed for this specific task, putting sight on increasing the accuracy of the called variant results. For instance, the Genome Analysis Toolkit, often known as GATK~\cite{mckenna2010genome}, and SAMtools~\cite{li2009sequence}, are some of the most popular tools for this certain task. Notwithstanding the efforts put in this problem, though, the results of those often turn out to have a rather low  precision-recall score, while disagreements were encountered between outcomes from different variant calling pipeline~\cite{o2013low}. In order to justify whether the called variant is likely to happen, there are a number of methods proposed to systematically assess the results~\cite{hwang2015systematic,yu2013comparing}. Moreover, there are also several methods proposed, acting as an additional process to the variant calling pipeline, to revise the called variants and boost the accuracy to some extent. They were shown to improve the results of the called variants after being applied at certain stages in the pipeline. This includes the predecessor of this study, EAGLE: Explicit Alternative Genome Likelihood Evaluator~\cite{kuo2018eagle}, published in 2017 by Tony Kuo et al. It is applied after the variant calling phrase, inspecting each of the called variant by evaluating their likelihood, according to the given reference genome. In comparison to the originally called variants, it is demonstrated that such post-processing improves the precision at an acceptible recall rate.
However, we noticed that the execution of EAGLE could take up to a decent amount of time, despite the usage of the provided multithreading option. Although the total execution time seems rather acceptible currently, we would like to further investigate potential oppurtunities of acceleration, regarding the upcoming third generation sequencing, where sequencing read lengths could easily grow up from those of NGS data around 100 base pairs all the way up to 10,000 base pairs. Furthermore, when we tried to make adjustments to the original program for other applications, an upserge in total execution time is repeatedly observed, making it difficult for more complex experiments.
Since sequence alignment is a highly parrallel task, it was already shown in the original EAGLE research that multithreading could effectively speedup the whole process. In order to further accelerate the program, adding more threads would be a straightforward approach. While the total amount of threads that can be ran concurrently is constrained by the hardware, it is often capped around tens to twenties for modern mainstream CPUs. This is far from enough in comparison to human genome sequences, motivating us to search for other sources of acceleration, including the usage of additional devices. 
This is when Graphics Processing Units, usually abbreviated as GPUs, come to our mind. Originally designed for graphics rendering, GPUs were first dedicated to graphics rendering pipeline. They are responsible for tasks such as vertex and fragment shading, rasterization, etc. The results were then mapped to the output devices, usually a computer monitor, where they are assembled to compute the value of each pixel, before the frame is presented to the user of the computer~\cite{foley1994introduction,owens2008gpu}. The job, being very computational expensive, depends heavily on the throughput that can be produced by the processors. Thus, the designation of GPU is mainly focused on the total amount of data throughtput, aiming to provide as many frames per second as possible, in order to provide a smooth screen that results in a better user experience. There exists multiple ways to achieve better data throughtput, applicable for different situations. When it comes to graphics rendering, which is a highly parallel task to compute values of RGB channels for each pixel presented to the screen, enabling more threads to execute the instructions concurrently is definitely a favorable direction. Hence, modern GPUs come with a lot more cores in comparison to CPUs. Although the computing power of a single GPU core is less than that of a single CPU core, with the total amount of cores outnumbering CPUs by a lot, plentiful of threads can be run at the same time due to having its own physical core, which is highly beneficial for data-parallel problems~\cite{navarro2014survey}. 
% GPU to general purpose
In the recent years, GPUs have been shown to greatly accelerate the process of a variety of tasks, including computer vision, deep learning, etc. Thus, we would like to investigate whether sequence alignment and variant calling, composed of several subtasks which are also highly data-parallel, can be can be accelerated with the aid of GPUs.
Here, we present a GPU accelerated version of EAGLE. To better integrate with the previous toolchain, most of the probablistic model would be rather similar to the original method, while several adjustments were made to reduce memory copy between device and host, making it a better fit to the device-host parellel computing architecture. This allows users from the previous program toggle between using the CPU entirely or enabling GPU acceleration, according to the distribution and the characteristic of the input data and the availability of GPU devices. Experiments were made by using both real data and simulated data, concluding that accelerating the likelihood evaluation process is beneficial when facing a massive sequencing read data.

\chapter{Related Works}
In this chapter, we review recent works related in brief.
\section{EAGLE}
\section{NVBIO}
\section{GASAL2}
In this research, 

\chapter{Method}
\section{Proposed Scheme}
In the original EAGLE publication, whether a hypothesis fits the sequenced read data is determined by its likelihood, often measured by its ratio against the default hypothesis: the read being sequenced from the reference genome. In order to compute the likelihood for all possible read alignments, the probabilities of all read and genome segment pair are calculated and then further summed up in logarithm. Although this is undoubtly a straightforward solution, numerous time consuming operations were done in loop. Here, we unroll the nested loops and take advantage of the high parallel graphics processing units. 
Before making any adjustments to the program, we would like to first take a closer look at the probablistic model proposed in EAGLE.

% Should I put the thorough probablistic model here?

First of all, for any given pair of genome segment g and sequence read r, the likelihood of the read being sequenced from g is computed by product of the likelihood of all base pairs. Since the likelihood of each bp match is independant to other bp matches, they can be computed concurrently. This provides us the oppurtunity to accelerate this process by computing them in parallel, where the maximum number of operations that can be done in parallel is bounded by the length of the read r. Considering NGS read data, which is often around 100 to 150 base pairs in terms of read length, we can easily load the entire read onto the GPU and allocate a thread for each base, since the size is rather small in comparison to the memory capacity and the core counts of modern GPUs.

Next, we would like to further extend the degree of parallelism, seeking to utilize the performance provided by the GPU. Here, we take a closer look at the intermediate result, p[r|G]. In most cases, knowing the exact genome segment g where read sequence r is sequenced from in advance is unrealistic. Thus, in the original method, for all possible genome segment g sampled from the hypothesis genome G, with the exact length with the given read r, were considered. P[r|g] are calculated iteratively, with the summation of their results being the final score of the given read. Since the total amount of segments to be considered is related to the length of read sequence(=2*lr), the execution time required grows in polynomial time with the sequence length. Apparently, the results of P[r|g] for different genome segment g is also independant, opening an oppurtunity for parallelism. In addition to the entire read r, we also loaded the selected genome G to the GPU, allocating a block of threads for each possible genome segment g. Within each block, we execute the same instructions as described in the previous section, calculating the probabilities for each site in their corresponding thread.

Through the above method, we have already reduced the amount of time required to execute the program. This also allows us to revisit a term that was previously ignored: insertion/deletion errors in read sequences. Since indel errors not only modifies the sequence but also introduce shifts, it would increase the time complexity, proportional to the length of reads. With the previous implementation, where the operations were sequentially executed, this would sure intensify the computational cost and lead to longer execution time. Mainly considering generation sequencing data, which has a rather low probability of indel errors in the sequencing phase, an assumption that there was no indel sequencing errors was made, in order to avoid the problem descibed above. However, with the aid of GPUs, such operations can be done concurrently, reducing the amount of time required to compute the final result. In GPU-EAGLE implementation, a threshold value is input by the user, indicating the maximum number of indel errors to be taken into account. After all, the probability of such errors is still fairly low, making it pointless to compute all of the combinations of shifted reads and indels. Knowing the threshold beforehand, all of the possible reads having less indel errors than it is then listed out and assigned to the GPU. Similar to the base case where no indel errors was considered, we would need a block of threads for each pair of read r and genome segment g. With regard to the same read having multiple variations due to the introduced indel errors, the GPU would launch a two dimensional block instead of the original one dimensional block, with the extra dimension representing the index of read in the list of possible reads with indel. To allow such indeled read list to be long exceeding the block size launched, either because of hardware constraints or user settings, the list would be partitioned to batches with the same size as the y dimensional size of the two dimensional block. At last, the results of each batch would be added up to acquire the final result.

\chapter{Results}
% Describe your results here.
\section{Input dataset}
To better compare the results with and without GPU acceleration, an experiment was conducted using the reconstructed diploid sequence of human genome chromosome 22 and hg19 reference sequence, which is one of the dataset that were used in the original study. Intend to investigate possible speedup when facing third generation sequencing read data, simulated sequencing reads with 10,000 base pairs were generated by random sampling from the reference genome. Reads with different lengths were also generated as a reference and an indicator for possible future generation sequencers.

\section{Benchmark platforms}
EAGLE-GPU is compiled with CUDA version 10.1. The experiments were conducted on a machine with a single AMD Ryzen™ 9 5950X desktop processor, consisting of 16 physical cores running at their base clock 3.4 gigahertz, and 128 GB of random access memory. The GPU installed on the machine is a single NVIDIA GeForce RTX™ 3090 graphics card.

\section{NS12911 variants with simulated NGS reads}


\section{Simulated reads with different lengths}

\section{Considering read indel errors}

\chapter{Discussion}
Discussion the significance or your results.
\section{Future Work}
Trying to investigate various possibilites of application for GPU to improve the performance, this paper provides the implementations of the general usage functions in CUDA. Unlike programs executed particularly on CPU, the design of GPU kernels often require extra attention, including memory copying schema and the detail implementation of algorithms. If we peurely consider datasets with shorter sequencing reads, the extent of parallelism could be further increased by computing different read sets concurrently. With a specific kernel for each case, warp divergence could be eliminated. Theoretically, this could benefit cases when the dataset consist of large amount of read sets, enormously reducing the amount of time to evaluate the likelihood by computing the results for each set all at once. Another possible optimization would be lessening the memory copying cost. Despite it not being the bottleneck of the program, some advanced techniques could be applied to lower the amount of data copied between the host CPU and the device even more. For example, if we are targeting only DNA and RNA sequences but not proteins, we could easily represent the bases, A, C, G, T(U for RNA), N, in 3 bits. Thus, instead of copying them as characters, they could be encoded first, enabling us to pack 2 bases into one unsigned integer. This is a common trick among sequencing related GPU applications, also adopted by other tools such as GASAL2 and NVBIO.

\chapter{Conclusion}
In this paper, we propose and implemented a GPU accelerated version of EAGLE, a previously proposed method for alternative genome likelihood evaluation. GPU-EAGLE utilizes the massively parallel architecture of modern GPUs, enabling instructions to be executed concurrently on multiple different data. This prepares the original method for the continuous growth when it comes to the size of sequencing data. Besides, we also investigated the feasibility of taking sequencing read indel errors into consideration, which is computational expensive and used to be ignored, after increasing the program throughput by applying parallel computation. We provide experimental results showing that GPU-EAGLE outperforms the CPU version when the data size is large enough, and conclude that designing a specialized GPU kernel could always be an option for forthcoming applications with excessive computational operations.

\newpage
\AddToContents{References}
\printbibliography


\end{document}
